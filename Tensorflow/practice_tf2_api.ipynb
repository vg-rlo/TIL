{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "revised-classroom",
   "metadata": {},
   "source": [
    "## Sequential API 활용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swiss-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fundamental-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist \n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test  = x_train/255.0, x_test/255.0\n",
    "\n",
    "x_train = x_train[..., np.newaxis]\n",
    "x_test = x_test[..., np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sacred-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential() \n",
    "\n",
    "model.add(keras.layers.Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(keras.layers.Conv2D(64, 3, activation = 'relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "hired-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "#     keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "#     keras.layers.Flatten(),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(10, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "occupational-pricing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "standing-italic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1074 - accuracy: 0.9675\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0343 - accuracy: 0.9893\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0202 - accuracy: 0.9936\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0132 - accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "313/313 - 2s - loss: 0.0604 - accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06040515750646591, 0.9853000044822693]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 5)\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-petroleum",
   "metadata": {},
   "source": [
    "## Functional API 활용하기 \n",
    "### 장점    \n",
    "* 덜 장황함\n",
    "* 연결성 그래프를 정의하는 동안 모델 검증\n",
    "* 기능적 모델은 플로팅 및 검사 가능\n",
    "* 기능 모델은 직렬화 또는 복제 가능\n",
    "\n",
    "### 단점 \n",
    "* 기능적 API는 모델을 계층의 DAG로 취급합니다.<br>\n",
    "이는 대부분의 딥 러닝 아키텍처에 해당되지만 전부는 아닙니다. 예를 들어 재귀 네트워크 또는 트리 RNN은이 가정을 따르지 않으며 기능 API에서 구현할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "trained-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End to End 예제\n",
    "model_input = keras.Input(shape = (28,28,1), name = \"input\")\n",
    "models = keras.layers.Conv2D(32, 3, activation = 'relu')(model_input)\n",
    "models = keras.layers.Conv2D(64, 3, activation = 'relu')(models)\n",
    "models = keras.layers.Flatten()(models)\n",
    "models = keras.layers.Dense(128, activation = 'relu')(models)\n",
    "models = keras.layers.Dense(10, activation = 'softmax')(models)\n",
    "\n",
    "model = keras.Model(inputs = model_input, outputs = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "classified-mixer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               4718720   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,738,826\n",
      "Trainable params: 4,738,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "correct-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1101 - accuracy: 0.9665\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0376 - accuracy: 0.9882\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9937\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0086 - accuracy: 0.9970\n",
      "313/313 - 0s - loss: 0.0504 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05044552683830261, 0.9886999726295471]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-royal",
   "metadata": {},
   "source": [
    "## Subclassing 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "noticed-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubclassModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation = 'relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.d1 = keras.layers.Dense(128, activation = 'relu')\n",
    "        self.d2 = keras.layers.Dense(10, activation = 'softmax')\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.d2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "numeric-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SubclassModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "municipal-biotechnology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1340 - accuracy: 0.9598\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0422 - accuracy: 0.9872\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0217 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0136 - accuracy: 0.9956\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0092 - accuracy: 0.9969\n",
      "313/313 - 0s - loss: 0.0647 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0646762028336525, 0.9832000136375427]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-performance",
   "metadata": {},
   "source": [
    "# CIFAR-100 데이터셋에 적용\n",
    "## Sequential API 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "studied-hundred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "editorial-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(16, 3, activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "model.add(keras.layers.Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(pool_size = (2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "leading-specification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.5973 - accuracy: 0.1606\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.8682 - accuracy: 0.2887\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.5638 - accuracy: 0.3538\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3564 - accuracy: 0.3957\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1946 - accuracy: 0.4294\n",
      "313/313 - 0s - loss: 2.5391 - accuracy: 0.3668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5390684604644775, 0.3668000102043152]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-burning",
   "metadata": {},
   "source": [
    "### Funtional API 활용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "wicked-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input((32, 32, 3))\n",
    "\n",
    "models = keras.layers.Conv2D(16, 3, activation = 'relu')(inputs)\n",
    "models = keras.layers.MaxPool2D(pool_size = (2,2))(models)\n",
    "models = keras.layers.Conv2D(32, 3, activation = 'relu')(models)\n",
    "models = keras.layers.MaxPool2D(pool_size = (2,2))(models)\n",
    "models = keras.layers.Flatten()(models)\n",
    "models = keras.layers.Dense(256, activation = 'relu')(models)\n",
    "models = keras.layers.Dense(100, activation = 'softmax')(models)\n",
    "\n",
    "model = keras.Model(inputs = inputs, outputs = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "german-toyota",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 3.6558 - accuracy: 0.1504\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.9332 - accuracy: 0.2780\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.6336 - accuracy: 0.3383\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.4266 - accuracy: 0.3786\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.2662 - accuracy: 0.4153\n",
      "313/313 - 0s - loss: 2.5783 - accuracy: 0.3510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.578341007232666, 0.35100001096725464]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "catholic-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubclassModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation = 'relu')\n",
    "        self.maxpool = keras.layers.MaxPool2D(pool_size = (2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation = 'relu')\n",
    "        self.flat = keras.layers.Flatten() \n",
    "        self.d1 = keras.layers.Dense(256, activation = 'relu')\n",
    "        self.d2 = keras.layers.Dense(100, activation = 'softmax')        \n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "circular-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SubclassModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "solved-tractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 3.6725 - accuracy: 0.1455\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.9556 - accuracy: 0.2722\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.6371 - accuracy: 0.3372\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.4417 - accuracy: 0.3807\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 2s 2ms/step - loss: 2.2850 - accuracy: 0.4112\n",
      "313/313 - 0s - loss: 2.5903 - accuracy: 0.3621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5902581214904785, 0.3621000051498413]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-evanescence",
   "metadata": {},
   "source": [
    "### Gradient Tape 활용 \n",
    "관련 분야: GAN, 강화학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "certified-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "reflected-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: last batch loss = 5.4639\n",
      "Epoch 1: last batch loss = 2.4900\n",
      "Epoch 2: last batch loss = 0.0083\n",
      "Epoch 3: last batch loss = 0.0127\n",
      "Epoch 4: last batch loss = 0.0755\n",
      "It took 73.92261695861816 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "brave-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1883"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
